{"posts":[{"title":"MySQL","text":"执行一条 select 语句，期间发生了什么？第一步：连接器连接的过程需要先经过 TCP 三次握手，因为 MySQL 是基于 TCP 协议进行传输的 第二步：查询缓存对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND 第三步：解析 SQL解析器第一件事情，词法分析。MySQL 会根据你输入的字符串识别出关键字出来，构建出 SQL 语法树，这样方面后面模块获取 SQL 类型、表名、字段名、 where 条件等等。第二件事情，语法分析。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 第四步：执行 SQL预处理器我们先来说说预处理阶段做了什么事情。 检查 SQL 查询语句中的表或者字段是否存在； 将 select * 中的 * 符号，扩展为表上的所有列优化器经过预处理阶段后，还需要为 SQL 查询语句先制定一个执行计划，这个工作交由「优化器」来完成的。 优化器主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。 逻辑优化查询：怎么查询效率更高 物理优化查询：索引等 执行器经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。接下来，用三种方式执行过程，跟大家说一下执行器和存储引擎的交互过程（PS ：为了写好这一部分，特地去看 MySQL 源码，也是第一次看哈哈）。 主键索引查询 全表扫描 索引下推 总结执行一条 SQL 查询语句，期间发生了什么？ 连接器：建立连接，管理连接、校验用户身份； 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块； 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型； 执行 SQL：执行 SQL 共有三个阶段： 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划； 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端； Mysql explain 执行计划 事务的四大特性？事务特性ACID：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。 一致性是指一个事务执行之前和执行之后都必须处于一致性状态。比如a与b账户共有1000块，两人之间转账之后无论成功还是失败，它们的账户总和还是1000。 隔离性。跟隔离级别相关，如read committed，一个事务只能读到已经提交的修改。 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。数据库范式 一范式、二范式、三范式、巴斯-科德范式、第四范式、第五范式（完美范式）「第一范式」：数据库中的字段具有「原子性」，不可再分，并且是单一职责 国家 省 市 区 街道 中国 上海 上海 宝山区 上大路99号 「第二范式」：「建立在第一范式的基础上」，第二范式要求数据库表中的每个实例或行必须「可以被唯一地区分」。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主键。（任何字段只能依赖主键） 订单编号 商品编号 用户ID 下单时间 商品名称 4654641666 4553 2424 2022-07-04 洗衣机 很显然，商品名称和订单无关，商品名称是依赖商品编号的，这是部分依赖！不应该放在同一张表格里面，应该拆成订单表和商品表。「第三范式」：「建立在第一，第二范式的基础上」，确保每列都和主键列直接相关，而不是间接相关不存在其他表的非主键信息其中总价是通过前面两个字段计算得到，数据库不要有数学计算的操作，业务需要的时候通过代码进行计算，不要入库 商品 单价 数量 总价 12456 10 50 500 但是在我们的日常开发当中，「并不是所有的表一定要满足三大范式」，有时候冗余几个字段可以少关联几张表，带来的查询效率的提升有可能是质变的 Order By 为什么会导致索引失效 字段： a\\b\\c\\d,索引：b\\c\\d 1EXPLAIN SELECT * FROM t1 ORDER BY b,c,d; 走bcd，不需要排序，n次回表 全表扫描，内存里排库 + 不用回表MySQL锁的类型 基于锁的分类：共享锁、排他锁 基于锁的粒度：行级锁、表级锁、页级锁、记录锁、间隙锁、临键锁 基于锁的状态：意向共享锁、意向排他锁 表级锁具体内容 表锁 123lock tables 表名…… read/writelock tables 表共享读锁 表独占写锁 元数据锁（共享锁）：在select和update时候都会自动加上 系统自动，无需显示使用，访问一张表会自动加上。当这张表上有未提交的事物，就不能修改表结构，被阻塞 意向锁 一个线程A给一行加了锁。另一个线程B想给整张表加锁，此时会有问题，B就要一帮一行找A给哪一行加了锁，很麻烦。 修改：在A给表加行锁的时候还会有一把意向锁，B要给表上锁的时候就会和意向锁进行兼容，兼容就说明可以给表上锁，否则不行，会处于阻塞状态，直到A行锁释放意向锁释放，B给表上锁 意向锁分为两种：意向共享锁和意向排他锁 意向共享锁：与表锁共享锁兼容，与表锁排他锁互斥 意向排他锁：与表锁共享锁、表锁排他锁互斥行级锁具体内容 行锁 共享锁： 排他锁： 间隙锁（一个范围，不包含该记录），确保索引间隙不变，防止其他事务在这个间隙进行insert导致幻读 临键锁：行锁+间隙锁，同时锁住数据和间隙 MySQL数据库中什么情况下索引无法使用 不符合最左匹配原则 字段进行了隐私数据类型转化 走索引没有全表扫描效率高 为什么B+树比B树更适合实现数据库索引？ 由于B+树的数据都存储在叶子结点中，叶子结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，而在数据库中基于范围的查询是非常频繁的，所以通常B+树用于数据库索引。 B+树的节点只存储索引key值，具体信息的地址存在于叶子节点的地址中。这就使以页为单位的索引中可以存放更多的节点。减少更多的I/O支出。 B+树的查询效率更加稳定，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 MyISAM和InnoDB myISAM InnoDB 不支持事务，每次查询都是原子的 ACID，事务，支持四种隔离级别 表锁 行锁，支持并发写 无MVCC MVCC 三个文件：索引文件、表结构文件、数据文件 除了主键以外，其他索引只存储索引内容 存储了表的总行数 没有存表行数 索引数据分开 主键索引文件存了所有的数据 注意：MyISAM引擎的主键索引，B+数的叶子节点存储的是主键和 什么是MVCC MVCC 多版本并发控制，读取的时候通过快照的方式将数据存下来，这样读锁写锁不冲突，不同事物session会看到自己的版本链 MVCC只在已提交读和可重复读两个隔离级别下工作 InnoDB在每行数据都增加三个隐藏字段，一个唯一行号，一个记录创建的版本号，一个记录回滚的版本号。 聚簇索引记录中有3个隐藏列 trx_id 和roll_pointer和ROW_ID trx_id：用来存储每一次对某条聚簇索引记录修改时的事务id roll_pointer：修改时，将老版本写入undo log中，roll_pointer存了一个指针，指向上一个版本记录的位置，通过它来获得上一条记录的信息 ROW_ID：隐藏主键，如果表结构没有指定主键，将会生成隐藏字段 已提交读和可重复读的区别在于他们生成的ReadView策略不同 开始事务时创建ReadView，维护事务的id（即未提交的事务），排成一个数组 已提交读：事务每次查询开始都声称一个独立的ReadView 可重复读：第一次读的时候生成一个ReadView，之后复用之前的ReadView 通过版本链实现并发读写。通过ReadView生成策略的不同实现不同的隔离级别 什么是脏读、幻读、不可重复读 脏读：一个事务修改了一个值，但是需要回滚 回滚前另一个事务读到了被修改后的值 幻读：一个事务插入了一条数据。插入前后另一个事务分别读取，读取的记录数不一样 不可重复读：一个事务修改前后，另一个事务读到的数据不一致 事务的基本特性和隔离级别 ACID 原子性：全执行/不执行 一致性： 隔离性：事务事物之间互不干扰 持久性：写在磁盘 隔离级别 读未提交：脏读 幻读 不可重复读 读已提交：幻读 不可重复读 可重复读：幻读(可通过临键锁解决) 串行化：（大量的锁 容易导致死锁）事务的实现原理事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。每当有修改事务时，还会产生undo log，如果需要回滚，则根据undo log 的反向语句进行逻辑操作，比如insert一条记录就delete一条记录。undo log主要实现数据库的一致性。 索引分类 功能逻辑上：普通索引、唯一索引、全文索引、单列索引 物理实现：聚簇索引、非聚簇索引 作用字段个数：单列索引、联合索引 普通索引：可以在任何数据类型唯一索引：该值必须唯一，允许有空值，比如邮箱、身份证、手机号主键索引：聚簇索引、非聚簇索引单列索引：一个字段联合索引：idx_id_name_gender 多个字段，使用要遵守最左前缀原则 什么是索引覆盖SQL执行的时候可以利用索引快速查找。字段在索引中都包含了，不需要回表，所有数据都在叶子节点上. 理解方式1：索引是高校找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此他不必读取整个行，毕竟索引叶子节点储存了他们的索引数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了，一个索引包含了满足查询结果的所有数据就叫组覆盖索引 理解方式2：非聚簇复合索引的一种形式，它包括在查询里的SELECT、JOIN、WHERE子句中做到所有列（即建索引的字段正好是覆盖查询条件中所涉及的字段） 简单地说就是：索引列+主键 包含SELECT到FROM之间的查询列 聚集索引、非聚集索引 InnoDB中，主键索引和每一条数据都放在同一个文件中。聚集索引的叶子节点包含了完整的数据记录 MyISAM的索引和主键分别放在myi和myd中，每次查询的时候从myi查到数据的存放位置，然后去myd中查出来，类似于一种回表的操作 聚簇索引和二级索引另外，索引又可以分成聚簇索引和非聚簇索引（二级索引），它们区别就在于叶子节点存放的是什么数据： 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点； 二级索引的叶子节点存放的是主键值，而不是实际数据。 因为表的数据都是存放在聚簇索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个。InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引： 如果有主键，默认会使用主键作为聚簇索引的索引键； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键； 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键； 一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。二级索引的 B+ 树如下图，数据部分为主键值：因此，如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据。 MySQL三大日志(binlog、redo log和undo log)详解 redo log:（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力。 比如 MySQL 实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的持久性与完整性。 MySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。 后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。 更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。 然后会把“在某个数据页上做了什么修改，比如页号xxx,偏移量yyy，写入了zzz数据”记录到重做日志缓存（redo log buffer）里，接着刷盘到 redo log 文件里。（物理级别的修改） binlog redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎。 而 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。 在事务执行的过程中，redo log会不断顺序记录，直到这个给事务提交，才会一次性写到bin log 中。 undo log 我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 回滚日志 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。 另外，MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改 MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。Mysql主从复制 (1) 为什么要做主从复制？1、在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。2、做数据的热备3、架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。(2) 什么是mysql的主从复制MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。(3) 主从复制原理 master服务器将数据的改变记录在二进制binlog日志上，当master上的数据发生改变时，将其写入二进制文件中; slave服务器会在一定时间间隔内对master二进制日志进行探测是否发生改变，如果发生改变，则开始一个I/O Thread请求master二进制事件 同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制时间，并保存至 从节点 本地的中继日志中，从节点 将启动sql线程从中继日志中读取二进制日志，在本地释放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。 简单说： 从库会生成两个线程,一个I/O线程,一个SQL线程; 主库会生成一个log dump线程,用来给从库I/O线程传binlog; I/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中; SQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行。 Innodb如何实现事务（update语句为例） Buffer Pool: update语句—&gt; 找到数据所在页-&gt; 缓存在Buffer Pool中 执行update语句 修改Buffer pool中的数据 针对update语句生成redolog对象，存入logBuffer中 针对update语句生成undo日志作为回滚使用 如果事务提交，Redolog持久化，后续有机制将BufferPool 中所修改的数据页持久化到磁盘中 如果事务回滚，则用undo日志进行回滚 Innodb 事务为什么要两阶段提交? 两段式提交，就是我们先把这次更新写入到redolog中，并设redolog为prepare状态，然后再写入binlog,写完binlog之后再提交事务，并设redolog为commit状态。也就是把redolog拆成了prepare和commit两段！ 其实redolog是后来才加上的，binlog是之前就有的。一开始存储引擎只有MyISAM,后来才有的InnoDB,然后MyISAM没有事务，没有crash-safe的能力。所以InnoDB搞了个redolog。然后为了保证两份日志同步，所以才有了两段式提交。 你假设一下如果先保存好redolog,然后再记录binlog。如果redolog写好了之后挂了。ok你看起来好像是没问题了，但是你的binlog还没记录，所以这条记录就少了！如果你备份这份binlog之后，你这条记录就永远的少了！ 那如果先写binlog再写redolog呢？那binlog写完了，你数据库挂了，那redolog是不是没有，没有的意思就是你以前你没更新成功。但是binlog已经记录好了，在它那边反正是成功了，所以那备份的binlog也不对！ WAl 是什么?有什么好处?WAI主要先写日志、再写磁盘 WAL(Write Ahead Log)预写日志，是数据库系统中常见的一种手段，用于：1、保证数据操作的原子性和持久性。2、使得随机写变为顺序写提高性能。WAL 的优点： 读和写可以完全地并发执行，不会互相阻塞（但是写之间仍然不能并发）。 WAL 在大多数情况下，拥有更好的性能（因为无需每次写入时都要写两个文件）。 磁盘 I/O 行为更容易被预测。 使用更少的 fsync()操作，减少系统脆弱的问题。什么是索引下推? INDEX CONDITION PUSHDOWN索引下推是 MySQL 5.6 版本中提供的一项索引优化功能，可以在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数。例如：1EXPLAIN SELECT * FROM S1 WHERE key1 &gt; 'z' AND key1 LIKE '%a'; 对于我们理解的而言，查询的顺序应该是： 先找到 key1 &gt; ‘z’的行，然后回表查询，最后筛选key1 LIKE ‘%a’的数据返回 但是对于查询优化器而言： 先找到 key1 &gt; ‘z’的行，这个时候先不回表，继续执行key1 LIKE ‘%a’，直接在索引中挑选出来，最后把符合这两个条件的数据进行回表查找。此时减少了回表的次数 例如：索引为zipcode,lastname,address 联合索引 索引中包含了后面查询田中的字段，在回表前索引下推机制是会先做判断的一条 Sql 语句查询偶尔慢会是什么原因? 数据库刷新脏页当我们要往数据库中插入一条数据或者更新一条数据时，数据库会在内存中把对应字段的数据更新了，但是更新完毕之后，这些更新的字段并不会马上同步持久化到磁盘中去，而是把这些更新的记录写入到redo log日志中去，只有等到空闲的时候才会通过redo log里的日志把最新的数据同步到磁盘里。这里redo log的容量是有限的，所以如果数据库一直很忙且更新有很频繁，那么这个时候redo log很快就会被写满，从而没办法等到空闲时再把数据同步到磁盘，只能暂停其他操作，全身心来把数据同步到磁盘中去，造成的表象就是我们平时正常的SQL语句突然会执行的很慢。也就是说，数据库在同步数据到磁盘的时候就有可能会导致我们的SQL语句执行的很慢。 无法获取锁资源执行的时候遇到了表锁或者行锁。如果我们要执行的SQL语句，其涉及到的表正好别人在用并且加锁了，或者表并没有加锁，但是要使用到的某一行被加锁了，那么我们便无法获取锁，只能慢慢等待别人释放锁了。如果要判断是否真的在等待锁资源，我们可以使用”show processlist”命令来查看当前的状态。主从延迟要怎么解决? 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询设置直连主库。不推荐这种方法，你要是这么搞，读写分离的意义就丧失了。 删除表数据后表的大小却没有变动,这是为什么?1、释放这些空间的操作本身就需要时间，如果每次删除数据都去进行这个操作，显然会影响性。2、第二个原因则是因为表里后续还是会有新的数据插入，这些删除的数据空间可以在新的数据插入进来后重新利用即可，这样也避免了新增数据要去重新申请新的空间。 为什么 VarChar 建议不要超过255?首先VARCHAR不是定长的，而是可变的，所以一般业务开发我们都要尽量使用最小的长度来满足需求，以免浪费空间，影响性能，而既然是可变的长度，那就得有保存长度的地方，所以如果VARCHAR的长度设置在255以下，那只会使用额外一个字节来保存长度，但是如果VARCHAR的长度设置在255以上，那么就会使用额外的两个字节来保存长度，无形中就浪费了存储空间。 Redis和MySQL如何保证数据的一致性问题：一份数据同时保存在数据库里和redis里面，数据发生变化的时候redis和MySQL变化是有先后顺序的 先更新数据库再更新缓存/先更新缓存再更新数据库 一个改还没同步，另一个查 不一致 先删除缓存再更新数据库 延时双删 保证高一致性：MQ手动应答确保redis删除Canal组件监听binlog日志","link":"/2022/05/20/Mysql/"},{"title":"Spring","text":"谈谈对AOP的理解 系统是由许多不同的组件所组成的，每一个组件各负责一块特定功能。除了实现自身校心功能之外，这些组件还经常承担者额外的指责。例如日志，事务管理和安全这样的核心服务经第融入到自身具有校心业务理相的组件中去。这些系统服务经第被称为横切关注点，因为它们会路越系統的多个组件。 当我们需要为分散的对象引入公共行为的时候，OOP则显得无能为力，也就是说，OOP允许你定义从上到下的关系，但井不适合定义从左到右的关系，例如日志功能。 日志代码往往水平地散布在所有层次中，而与它所散布到的对象的校心功能无关系。 在OOP设计中，已导致了大量代码的重复，而不利于各个模块的重用。 AOP：将程序中的交叉业务设得(比如安全，日志，事务等），封装成一个切面，然后注入到目标对象（具体业务逻得）中去。AOP可以对某个对象或某些对象的功能进行增强，比如对象中的方法进行增强，可以在执行某个方法之前额外的做一些事情，在某个方法执行之后额外的做一些事情 AOP有哪些实现方式AOP是通过动态代理实现的，代理模式是一种设计模式，它提供了对目标对象额外的访问方式，即通过代理对象来访问目标对象，这样可以在不修改原目标对象的情况下提供额外的功能。静态代理与动态代理区别： 静态代理在编译时就实现了，编译完后是一个实际的.class文件。 动态代理是运行时生成的，即编译完以后没有实际的.class文件，而是生成类字节码，并加载到jvm中。 静态代理 指使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强; 动态代理 在运行时在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。 JDK 动态代理：通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是 InvocationHandler 接口和 Proxy 类。 CGLIB 动态代理：如果月标类没有实现接口，那么spring AoP 会选择使用 CGLIB 来动态代理目标类。CGLIB(Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意， CGLIB 是通过继承的方式做的动态代理，因此如果某个类被标记为 final，那么它是无法使用CGLTB 做动态代理的。 谈谈对IOC的理解容器概念、控制反转、依赖注入 IOC容器： 实际上就是个map (key， value），里面存的是各种对象（在xml里配置的bean节点、@repository、@service.@controller. @component)，在项目启动的时候会读取配置文件里面的bean节点，根据全限定类名使用反射创建对象放到map里、扫描到打上上述注解的类还是通过反射创建对象放到map里 这个时候map里就有各种对象了，接下来我们在代码里需要用到里面的对象时，再通过DI注入 (autowired、resource等注解，xml里bean节点内的ref属性，项目启动的时候会读取xml节点ref厲性根据id注入，也会扫描这些注解，根据类型或id注入；id就是对象名）。 控制反转： 没有引入IOC容器之前，对象A依赖于对象B，那么对象A在初始化或者运行到某一点的时候，自己必须主动去创建对象B或者使用已经创建的对象B。无论是创建还是使用对象B，控制权都在自己手上 引入IOC容器之后，对象A与对象B之间失去了直接联系，当对象A运行到需要对象B的时候，IOC容器会主动创建一个对象B注入到对象A需要的地方。通过前后的对比，不难看出来：对象A获得依赖对象B的过程,由主动行为变为了被动行为，控制权颠倒过来了，这就是控制反转这个名称的由来。 全部对象的控制权全部上缴给”第三方”IOC容器，所以，IOC容器成了整个系统的关键核心，它起到了一种类似”粘合剂”的作用，把系统中的所有对象粘合在一起发挥作用，如果没有这个”粘合剂”，对象与对象之间会彼此失去联系，这就是有人把IOC容器比喻成”粘合剂”的由来。 依赖注入： 获得依赖对象的过程被反转了。控制被反转之后，获得依赖对象的过程由自身管理变为了由IOC容器主动注入。依赖注入是实现IOC的方法，就是由容器在运行期间，动态地将某种依赖注入到对象之中。 Spring加载Bean的过程bean的定义信息：xml 注解 BeanFactory FactoryBean区别BeanFactory：必须遵循完整的Bean生命周期去创建对象，流水线式创建。FactoryBean：创建对象但是没有标准的流程，类似私人定制。 isSingleton 判断是否单例 getObjectType 返回对象的类型 getObject 返回对象 Spring Bean的生命周期 创建前准备、创建实例、依赖注入、容器缓存、销毁实例 Spring 容器 从 XML 文件中读取 bean 的定义BeanDefinition，并实例化 bean。 Spring 根据 bean 的定义填充所有的属性（对对象中加入Autowried注解的属性进行自定义属性填充）。 调用Aware方法，如果 bean 实现了 BeanNameAware 接口，Spring 传递 bean 的 ID 到 setBeanName 方法；如果 Bean 实现了 BeanFactoryAware 接口， Spring 传递 beanfactory 给 setBeanFactory 方法。（设置容器属性） 如果有任何与 bean 相关联的 BeanPostProcessors，Spring 会在 postProcesserBeforeInitialization()方法内调用它们。（初始化前的方法） 如果 bean 实现 IntializingBean 了，调用它的 afterPropertiesSet 方法， 如果 bean 声明了初始化方法，调用此初始化方法。 （初始化方法） 如果有 BeanPostProcessors 和 bean 关联，这些 bean 的 postProcessAfterInitialization() 方法将被调用。 （初始化后方法，这里会进行AOP） 如果当前创建的bean是单例的，把bean放入单例池 使用bean 如果 bean 实现了 DisposableBean，它将调用 destroy()方法。 什么是Bean的自动装配，有哪些方式Spring 容器能够自动装配相互合作的 bean，这意味着容器不需要和配置，能通 过 Bean 工厂自动处理 bean 之间的协作。 1&lt;bean id = &quot;book&quot; class = &quot;com.xxx.xxx.Book&quot; autowrire = &quot;&quot;&gt; no：默认的方式是不进行自动装配，通过显式设置 ref 属性来进行装配。 byName：通过参数名 自动装配，Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byname，之后容器试图匹配、装配和该 bean 的属性具有相同名字的 bean。 byType：通过参数类型自动装配，Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byType，之后容器试图匹配、装配和该 bean 的属性具有相同类型的 bean。如果有多个 bean 符合条件，则抛出错误，使用@Qualifire注解指定 一个去注入。 constructor：这个方式类似于 byType， 但是要提供给构造器参数，如果没有确定的带参数的构造器参数类型，将会抛出异常。 autodetect：首先尝试使用 constructor 来自动装配，如果无法工作， 则使用 byType 方式。 Spring中的Bean是线程安全的吗Spring本身并没有针对Bean做线程安全的处理，所以 如果Bean是无状态的，则Bean是线程安全的 有状态，则不安全 另外，Bean是不是线程安全跟Bean作用域没关系，Bean作用域只是表示Bean生命周期的范围 Spring支持的几种bean的作用域 singleton : bean在每个Spring ioc 容器中只有一个实例。单例模式由BeanFactory自身来维护。该对象的生命周期和IOC一致。（在第一次被注入时才会被创建） prototype：为每一个bean请求提供一个实例。在每次注入时都会创建一个新的对象。 request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。 session：在一个HTTP Session中，一个bean定义对应一个实例。session过期以后bean会随之失效 global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。 注意： 缺省的Spring bean 的作用域是Singleton。使用 prototype 作用域需要慎重的思考，因为频繁创建和销毁 bean 会带来很大的性能开销。 Spring用到哪些设计模式Spring如何解决循环依赖关键词：三级缓存、提前暴露对象、AOP 总：什么是循环依赖？ A有b属性，B有a属性 bean的创建过程是先实例化–&gt;初始化 A在实例化后初始化时b属性为空，去容器中找B对象 有B，不存在循环依赖 无B，创建B，填充a属性 —&gt;容器中去找A 找不到 仔细思考发现A对象是存在的，不过不是一个完整状态，只完成了实例化，没有完成初始化。如果调用了某个对象的引用，后期可以先把非完整状态赋值，等后续操作来完成赋值，相当于提前暴露了某个不完整对象的引用。所以解决问题的核心在于实例化和初始化分开操作 当所有对象都完成操作实例化之后，还要把对象放入容器中，此时容器中的对象有两个状态 实例化完成但未初始化完成 实例化初始化都完成 这两种对象都在容器中，所以要用不同的map结构来进行存储，此时就有一级缓存和二级缓存 一级缓存放完整的对象 二级缓存放非完整对象 三级缓存中的value类型是ObjectFactory函数式接口，存在的意义是保证在容器中同名的bean对象只有一个，一个对象如果要被代理，或者说要生成代理对象，那么先需要一个普通对象。普通对象和代理对象不能同时出现在容器中，因此一个对象需要被代理时就需要使用代理对象去覆盖之前的普通对象，在实际调用中是没有办法确定什么时候对象被调用，所以就需要当某个对象被调用时优先判断此对象是否需要被代理，类似一种回调机制的实现，因此传入lambda表达式时可以通过lambda表达式来执行对象覆盖过程 因此所有bean对象在创建时都放在三级缓存中，后续使用中需要被代理则返回代理对象，不需要则返回普通对象 Spring事务的实现方式和原理以及隔离级别有两种使用事务的方式：编程式和申明式 编程式就是调用一些API 申明式例如@Transaction（rollback = “”） Spring事务隔离级别就是数据库的隔离级别。如果数据库配置RC，Spirng配置RR，则以Spring配置为准，如果Spring设置的隔离级别数据库不支持，那么以数据库为准。 Spring事务传播机制Spring Boot、Spring MVC、Spring区别 spring是一个lOC容器，用来管理Bean，使用依赖注入实现控制反转，可以很方便的整合各种框架，提供AOP机制弥补oOP的代码重复问题、更方便将不同类不同方法中的共同处理抽取成切面、自动注入给方法执行，比如日志、异常等 springmvc是spring对web框架的一个解决方案，提供了一个总的前端控制器Servlet，用来接收请求，然后定义了一套路由策略(url到handle的映射)及适配执行handle，将handle结果使用视图解析技术生成视图展现给前端 springboot是spring提供的一个快速开发工具包，让程序员能更方便、更快速的开发spring+springmvc应用，简化了配置(约定了默认配置)，整合了一系列的解决方案(starter机制) 、 redis、mongodb、es，可以开箱即用Spring MVC工作流程 流程说明（重要）: 客户端（浏览器）发送请求，直接请求到Dispatcherservlet。 Dispatcherservlet根据请求信息调用HandlerMapping，拿到控制链。&lt;url，handler&gt;的一个Map Dispatcherservlet调用HandlerAdapter适配器处理 解析到对应的Handler(也就是我们平常说的Controller控制器） Controller执行完成返回ModelAndView HandlerAdapter会根据把ModelAndView返回给Dispatcherservlet ViewResolver会根据逻辑view查找实际的view。 Dispaterservlet把返回的Model传给view（视图渲染） 把view返回给请求者（浏览器) Spring MVC主要组件 SpringBoot自动配置原理@SpringBootApplication可以看作是 @SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan 注解的集合。根据 SpringBoot 官网，这三个注解的作用分别是： @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制 @SpringBootConfiguration：允许在上下文中注册额外的 bean 或导入其他配置类 @ComponentScan： 扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除TypeExcludeFilter和AutoConfigurationExcludeFilter。 @EnableAutoConfigurationSpring中有很多Enable开头的注解其作用就是借助@Import来收集并注册特定场景相关的Bean，并加载到IOC容器。@EnableAutoConfiguration就是借助@lmport来收集所有符合自动配置条件的bean定义，并加载到IOC容器。 @Import（AutoConfigurationImportSelector.class） 帮助SpringBoot将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IOC容器中。 AutoConfigurationImportSelector类实现了Aware相关接口 其中getImports()中调用selectImports() @AutoConfigurationPackage @Import：导入Registar组件 就干一件事：拿到启动类所在的包名。 SpringBoot常用注解及其底层实现原理1.@SpringBootApplication注解:这个注解标识了一个SpringBoot工程，它实际上是另外三个注解的组合，这三个注解是: @SpringBootConfiguration:这个注解实际就是一个@Configuration，表示启动类也是一个配置类 .@EnableAutoConfiguration:向Spring容器中导入了一个Selector，用来加载Classpath 下SpringFactories中所定义的自动配置类，将这些自动加载为配置Bean @ComponentScan:标识扫描路径，因为默认是没有配置实际扫描路径，所以SpringBoot扫描的路径是启动类所在的当前目录 2.@Bean注解:用来定义Bean，类似于XML中的标签，Spring在启动时，会对加了@Bean注解的方法进行解析，将方法的名字做为beanName，并通过执行方法得到bean对象3.@Controller、@Service、@ResponseBody、@Autowired都可以说 如何理解SpringBoot中的starter 使用spring + springmvc使用，如果需要引入mybatis等框架，需要到xml中定义mybatis需要的bean starter就是定义一个starter的jar包，写一个@Configuration配置类、将这些bean定义在里面，然后在starter包的META-INF/spring.factories中写入该配置类,springboot会按照约定来加载该配置类 开发人员只需要将相应的starter包依赖进应用，进行相应的属性配置（使用默认配置时，不需要配置)，就可以直接进行代码开发，使用对应的功能了，比如mybatis-spring-boot-starter，spring-boot-starter-redisSpringboot的启动流程细节 1、SpringBoot启动的时候，会构造一个SpringApplication的实例，然后调用这个实例的run方法，在run方法调用之前，也就是构造SpringApplication的时候会进行初始化的工作，初始化的时候会做以下几件事：(1)把参数sources设置到SpringApplication属性中，这个sources可以是任何类型的参数.(2)判断是否是web程序，并设置到webEnvironment的boolean属性中.(3)创建并初始化ApplicationInitializer，设置到initializers属性中 。(4)创建并初始化ApplicationListener，设置到listeners属性中 。(5)初始化主类mainApplicatioClass。2、SpringApplication构造完成之后调用run方法，启动SpringApplication，run方法执行的时候会做以下几件事：(1)构造一个StopWatch计时器，观察SpringApplication的执行 。(2)获取SpringApplicationRunListeners并封装到SpringApplicationRunListeners中启动，用于监听run方法的执行。(3)创建并初始化ApplicationArguments,获取run方法传递的args参数。(4)创建并初始化ConfigurableEnvironment（环境配置）。(5)打印banner（只用在Classpath下添加字符文件图标，就可以在启动时候打印）。(3)构造Spring容器(ApplicationContext)上下文。(4)SpringApplicationRunListeners发布finish事件。(5)StopWatch计时器停止计时。 MyBatis优缺点优点: 基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理;提供XML标签，支持编写动态SQL语句，并可重用。 与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接; 很好的与各种数据库兼容（因为MyBatis 使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持)。 能够与Spring很好的集成; 供映射标签，支持对象与数据库的ORM字段关系映射;提供对象关系映射标签，支持对象关系组件维护。 缺点: SQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求。 SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。 #{} 和 ${}区别 #{}是预编译处理是占位符，${}是字符串替换、是拼接符。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement来赋值，会有预编译，#对应的变量自动加上单引号； Mybatis在处理${}时，就是把${}替换成变量的值，是动态参数（比如通过传参动态设置表名，动态设置排序字段），调用Statement来赋值，相当于直接拼接，${}对应的变量不会加上单引号； 使用#{}可以有效的防止SQL注入，提高系统安全性。 MyBatis二级缓存Mybatis 中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存 是指 SqlSession 级别的缓存，当在同一个 SqlSession 中进行相同的 SQL 语句查询时，第二次以 后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存 1024 条 SQL。二级缓存 是指可以跨 SqlSession 的缓存。是 mapper 级别的缓存，对于 mapper 级别的缓存不同的 sqlsession 是可以共享的","link":"/2022/05/22/Spring/"},{"title":"计算机网络","text":"分层 键入网址到网页显示，期间发生了什么？1、首先，在浏览器地址栏中输入url2、浏览器先查看浏览器缓存-系统缓存-路由器缓存，如果缓存中有，会直接在屏幕中显示页面内容。若没有，则跳到第三步操作。3、在发送http请求前，需要域名解析(DNS解析)，解析获取相应的IP地址。4、浏览器向服务器发起tcp连接，与浏览器建立tcp三次握手。5、握手成功后，浏览器向服务器发送http请求，请求数据包。6、服务器处理收到的请求，将数据返回至浏览器7、浏览器收到HTTP响应8、读取页面内容，浏览器渲染，解析html源码9、生成Dom树、解析css样式、js交互10、客户端和服务器交互 TCPTCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。 TCP 连接建立TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图： 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。 服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。 从上面的过程可以发现第三次握手是可以携带数据的，前两次握手是不可以携带数据的，这也是面试常问的题。 为什么是三次握手？不是两次、四次？ 三次握手才可以阻止重复历史连接的初始化（主要原因） 三次握手才可以同步双方的初始序列号 三次握手才可以避免资源浪费 阻止重复历史连接的初始化（主要原因）简单来说，三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。我们考虑一个场景，客户端先发送了 SYN（seq = 90） 报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100） 报文（注意不是重传 SYN，重传的 SYN 的序列号是一样的）。客户端连续发送多次 SYN 建立连接的报文，在网络拥堵情况下： 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端； 那么此时服务端就会回一个 SYN + ACK 报文给客户端； 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，表示中止这一次连接。 如果是两次握手连接，就无法阻止历史连接，那为什么 TCP 两次握手为什么无法阻止历史连接呢？主要是因为在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费。 同步双方的初始序列号TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用： 接收方可以去除重复的数据； 接收方可以根据数据包的序列号按序接收； 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）； 可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。 避免资源浪费如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。 小结TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。不使用「两次握手」和「四次握手」的原因： 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。 第一次握手丢失会发生什么当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 SYN_SENT 状态。在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文。通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，每次超时的时间是上一次的 2 倍。 第二次握手丢失会发生什么当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 SYN_RCVD 状态。第二次握手的 SYN-ACK 报文其实有两个目的 ： 第二次握手里的 ACK， 是对第一次握手的确认报文； 第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文； 因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。 第三次握手丢失会发生什么客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。 SYN攻击攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的半连接队列，使得服务器不能为正常用户服务。正常流程： 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」； 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文； 服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」； 应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接。 避免方式： 修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」，计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端。服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」，最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。TCP 连接断开TCP 断开连接是通过四次挥手方式。双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图： 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。 每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。 为什么是四次 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。 第一次挥手丢失会发生什么当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，直接进入到 close 状态。 第二次挥手丢失会发生什么当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。在前面我们也提了，ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 FIN_WAIT2 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。对于 close 函数关闭的连接，由于无法再发送和接收数据，所以FIN_WAIT2 状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长，默认值是 60 秒。这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭。但是注意，如果主动关闭方使用 shutdown 函数关闭连接且指定只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态（tcp_fin_timeout 无法控制 shutdown 关闭的连接）。 第三次挥手丢失会发生什么当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。 第四次挥手丢失会发生什么当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。 为什么 TIME_WAIT 等待的时间是 2MSL？MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。 为什么要TIME_WAIT状态 防止历史连接中的数据，被后面相同四元组的连接错误的接收； 保证「被动关闭连接」的一方，能被正确的关闭； TCP为啥是可靠的TCP 是一个可靠传输的协议，那它是如何保证可靠的呢？为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。那么，TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。 重传机制TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？所以 TCP 针对数据包丢失的情况，会用重传机制解决。 超时重传上图中有两种超时时间不同的情况： 当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差； 当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 精确的测量超时时间 RTO 的值是非常重要的，这可让我们的重传机制更高效。根据上述的两种情况，我们可以得知，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。 快速重传 第一份 Seq1 先送到了，于是就 Ack 回 2； 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2； 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到； 发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。 最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。 快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题。比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。 SACK选择性确认这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。 滑动窗口我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。但这种方式的缺点是效率比较低的。为解决这个问题，TCP 引入了窗口这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。那么有了窗口，就可以指定窗口大小，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。 #1 是已发送并收到 ACK确认的数据：1~31 字节 #2 是已发送但未收到 ACK确认的数据：32~45 字节 #3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节 #4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后 在下图，当收到之前发送的数据 3236 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认，接下来 5256 字节又变成了可用窗口，那么后续也就可以发送 52~56 这 5 个字节的数据了。TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。 流量控制发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。 拥塞控制一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 慢启动TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。可以看出慢启动算法，发包的个数是指数性的增长。有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。 当 cwnd &lt; ssthresh 时，使用慢启动算法。 当 cwnd &gt;= ssthresh 时，就会使用「拥塞避免算法」。 拥塞避免算法前面说道，当拥塞窗口 cwnd 「超过」慢启动门限 ssthresh 就会进入拥塞避免算法。一般来说 ssthresh 的大小是 65535 字节。那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1/cwnd。接上前面的慢启动的栗子，现假定 ssthresh 为 8： 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。 所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。 拥塞发生当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种： 超时重传 快速重传 当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh 和 cwnd 的值会发生变化： ssthresh 设为 cwnd/2， cwnd 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1） 快速恢复快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。正如前面所说，进入快速恢复之前，cwnd 和 ssthresh 已被更新了： cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 然后，进入快速恢复算法如下： 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态； UDP TCP？ UDP是无连接的； UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）； UDP是面向报文的； UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）； UDP支持一对一、一对多、多对一和多对多的交互通信； UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 那么，再说一次TCP的特点： TCP是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）； 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）； TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达； TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据； 面向字节流。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 TCP Keepalive 和 HTTP Keep-Alive事实上，这两个完全是两样不同东西，实现的层面也不同： HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接； TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制； HTTP 的 Keep-Alive Http 1.0 短链接 Http 1.1 长链接 HTTP 的 Keep-Alive 可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。从 HTTP 1.1 开始， 就默认是开启了 Keep-Alive。为了避免资源浪费的情况，web 服务软件一般都会提供 keepalive_timeout 参数，用来指定 HTTP 长连接的超时时间。比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会启动一个定时器，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。 TCP 的 Keepalive如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。 所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。 总结 HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。 TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。HTTP 与 HTTPSHTTP 与 HTTPS 区别 HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 HTTP 的端口号是 80，HTTPS 的端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。 HTTP 由于是明文传输，所以安全上存在以下三个风险： 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险： 信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。 身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。 HTTPS 混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。 混合加密通过混合加密的方式可以保证信息的机密性，解决了窃听的风险。HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式： 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 采用「混合加密」的方式的原因： 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。摘要算法那么，在计算机里会用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容。 通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。数字证书在计算机里，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。Cookie与Session的对比HTTP作为无状态协议，必然需要在某种方式保持连接状态。这里简要介绍一下Cookie和Session。 Cookie Cookie是客户端保持状态的方法。Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是会话Cookie一种是持久Cookie，会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁，持久Cookie则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代理所共享的。 Session Session是服务器保持状态的方法。首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的Session用户在客户端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。 当服务器需要识别客户端时就需要结合Cookie了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。","link":"/2022/05/21/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"title":"操作系统","text":"进程、线程、协程进程是系统资源分配和调度的最小单位、线程是操作系统分配和调度的最小单位线程分成更小的协程，多个协程共享一个线程。线程切换是一个操作系统层面的行为，要关中断、保存断点、终端服务寻址、开中断执行服务协程间切换是runtime的 行为 操作系统运行机制 时钟管理 中断机制 外中断：中断信号来源于外部设备（被迫的） 内中断：中断信号来源于当前指令（自愿的）： 陷入指令（应用程序引发的，cpu产生），比如程序执行到某处需要进行读文件操作，cpu从用户态切换到内核态 内存缺页中断 原语（原语的底层实现就是靠开中断和关中断实现的） 若干条指令组成 完成某个特定功能 执行过程不会被中断（具有原子性） 系统数据结构 进程管理：作业控制快、进程控制块 存储器管理：存储器分配与回收 设备管理：缓冲区、设备控制快 系统调用（应用程序去访问操作系统内核的时候） 一套接口的集合 应用程序去访问操作系统内核服务的方式操作系统 PCB:为了描述控制进程的运行，系统中存放进程的管理和控制信息的数据结构称为进程控制块（PCB Process Control Block），它是进程实体的一部分，是操作系统中最重要的记录性数据结构。它是进程管理和控制的最重要的数据结构，每一个进程均有一个PCB，在创建进程时，建立PCB，伴随进程运行的全过程，直到进程撤消而撤消。寄存器里面放的是有些程序运行计算了一半被抢占了，记录执行的位置，下次执行可以接着中间数据往下执行 进程的状态 其实是七状态，还有阻塞挂起和就绪挂起 进程间通信共享存储：共享空间对于多个进程访问是互斥的 管道通信：没写满的时候是不允许读的，没读完也是不允许写的。 消息队列：消息头里包含了传递信息，不会传错给别的进程 信号套接字 socket线程 线程的实现方式（用户级线程、内核级线程、组合方式） 多线程模型：多对一、一对多n个用户级线程映射到内核级线程上 处理机调度（线程调度） 进程同步 **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 信号量(Semaphore) ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 临界区：拥有临界区的线程可以访问被保护资源，其他访问会被挂起。 双标志前检查法：先检查其他进程是否想要临界区，再上锁 双标志后检查法：先上锁在检查其他进程是否想要临界区 Peterson算法：双方都争着使用临界区的话，可以尝试让一方主动让对方先使用临界区进程互斥临界区冲突 空闲让进：一次进一个，进不来的挂起 忙则等待： 有限等待：有限时间内退出 让权等待：进程不能进入自己的临界区，则应该让出CPU，避免出现忙等现象 死锁 互斥条件：对必须互斥资源的争抢才会导致死锁 不剥夺条件：进程获得的资源在未使用完之前不能由其他进程强行夺走，只能主动释放 请求和保持条件：进程已经保持至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求被阻塞，但又对自己的资源保持不放 循环等待条件：存在资源的循环等待链 预防死锁 避免死锁（银行家算法） 死锁的检测内存 内存管理 覆盖技术下图A调用B、C是依次调用的，因此B、C可以共同使用程序X的覆盖区0（图中绿色），从逻辑上看，物理内存是被”拓展“了 交换技术 换入、换出 内存分配管理方式（单一连续分配、固定分区分配方式） 分页不同的页面是离散地存放在内存中 页表每个进程都有自己的页表 两级页表问题：相当于把以前的页表查分成多个页表，并为多个页表加一个目录，叫做”页目录表“ 虚拟内存传统存储例如，GTA游戏一共60G，电脑是4G的，如果要玩的话需要全部加载到内存中，显然是不够的，但是我在A场景时只用放入A场景的资源就可以了，而这种传统方式会需要整个游戏全部加驻留在内存中。虚拟内存基于局部性原理 实现虚拟内存的技术请求分页存储管理 内存有空闲的情况 内存没空闲的情况 请求分段存储管理请求段页式存储管理页面替换算法最佳置换算法（OPT） 先进先出置换算法（FIFO） 最近最久未使用置换算法（LRU） 时钟置换算法（CLOCK） 内存块排布类似于循环链表 到6页面的时候，由于5个内存块都满了，就需要先箭头转一圈全部置为0，然后替换最开始的位置，后面用到的继续置为1，全为1的时候再转一圈变为0，然后又从队首开始替换。箭头扫描的过程有点像时钟转，故命名为时钟置换算法。改造型的时钟置换算法因为之前说到分页存储的时候，再替换过程中如果一个页面被修改过，则需要写入外存中去。这个时候给他加一个标记，被修改过的时候修改位标记为1。磁盘结构活动头磁盘、固定头磁盘写磁盘需要的时间流程（寻道时间、延迟时间、传输时间）磁盘调度算法先来先服务最短寻找时间优先扫描算法LOOK调度算法（扫描算法改进）循环扫描算法（扫描算法改进）主要是各个磁道响应时间比较平均C-LOOK调度算法总结减少磁盘延迟时间的方法交替编号：在读取连续扇区时，每读完一个扇区需要时间处理读取的内容，由于磁头还没有准备好，可能在处理过程中就错过了连续扇区的内容，这个时候需要再转一圈转到未读的地方，所以一般间隔编号依次交替解决问题错位命名 IOselect poll epoll 什么是操作系统？请简要概述一下操作系统是管理计算机硬件和软件资源的计算机程序，提供一个计算机用户与计算机硬件系统之间的接口。向上对用户程序提供接口，向下接管硬件资源。操作系统本质上也是一个软件，作为最接近硬件的系统软件，负责处理器管理、存储器管理、设备管理、文件管理和提供用户接口。 操作系统有哪些分类？操作系统常规可分为批处理操作系统、分时操作系统、实时操作系统。若一个操作系统兼顾批操作和分时的功能，则称该系统为通用操作系统。常见的通用操作系统有：Windows、Linux、MacOS等。 什么是内核态和用户态？为了避免操作系统和关键数据被用户程序破坏，将处理器的执行状态分为内核态和用户态。内核态是操作系统管理程序执行时所处的状态，能够执行包含特权指令在内的一切指令，能够访问系统内所有的存储空间。用户态是用户程序执行时处理器所处的状态，不能执行特权指令，只能访问用户地址空间。用户程序运行在用户态,操作系统内核运行在内核态。 如何实现内核态和用户态的切换？处理器从用户态切换到内核态的方法有三种：系统调用、异常和外部中断。 系统调用是操作系统的最小功能单位，是操作系统提供的用户接口，系统调用本身是一种软中断。 异常，也叫做内中断，是由错误引起的，如文件损坏、缺页故障等。 外部中断，是通过两根信号线来通知处理器外设的状态变化，是硬中断。 并发和并行的区别 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，指令之间交错执行，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率（如降低某个进程的相应时间）。 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。 什么是进程？进程是操作系统中最重要的抽象概念之一，是资源分配的基本单位，是独立运行的基本单位。进程的经典定义就是一个执行中程序的实例。系统中的每个程序都运行在某个进程的上下文（context）中。上下文是由程序正确运行所需的状态组成的。这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合。进程一般由以下的部分组成： 进程控制块PCB，是进程存在的唯一标志，包含进程标识符PID，进程当前状态，程序和数据地址，进程优先级、CPU现场保护区（用于进程切换），占有的资源清单等。 程序段 数据段 进程的基本操作以Unix系统举例： 进程的创建：fork()。新创建的子进程几乎但不完全与父进程相同。子进程得到与父进程用户级虚拟地址空间相同的(但是独立的)一份副本，包括代码和数据段、堆、共享库以及用户栈。子进程还获得与父进程任何打开文件描述符相同的副本，这就意味着当父进程调用 fork 时，子进程可以读写父进程中打开的任何文件。父进程和新创建的子进程之间最大的区别在于它们有不同的 PID。fork函数是有趣的（也常常令人迷惑）， 因为它只被调用一次，却会返回两次：一次是在调用进程（父进程）中，一次是在新创建的子进程中。在父进程中，fork 返回子进程的 PID。在子进程中，fork 返回 0。因为子进程的 PID 总是为非零，返回值就提供一个明 确的方法来分辨程序是在父进程还是在子进程中执行。 复制代码回收子进程：当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程被保持在一种已终止的状态中，直到被它的父进程回收（reaped）。当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程。一个进程可以通过调用 waitpid 函数来等待它的子进程终止或者停止。 1 pid_t fork(void); 复制代码加载并运行程序：execve 函数在当前进程的上下文中加载并运行一个新程序。复制代码进程终止： 1 pid_t waitpid(pid_t pid, int *statusp, int options); 1 int execve(const char *filename, const char *argv[], const char *envp[]); 复制代码每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核,在内核中开辟一块缓冲区,进程A把数据从用户空间拷到内核缓冲区,进程B再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信。 不同进程间的通信本质：进程之间可以看到一份公共资源；而提供这份资源的形式或者提供者不同，造成了通信方式不同。 进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。 管道是一种最基本的IPC机制，作用于有血缘关系的进程之间，完成数据传递。调用pipe系统函数即可创建一个管道。有如下特质： 管道的原理: 管道实为内核使用环形队列机制，借助内核缓冲区实现。 管道的局限性： 它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。 特点： 一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。Linux 系统上支持的30 种不同类型的信号。每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。 复制代码进程在运行时有三种基本状态：就绪态、运行态和阻塞态。 2.就绪（ready）态：进程具备运行条件，等待系统分配处理器以便运行的状态。 当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。 3.阻塞（wait）态：又称等待态或睡眠态，指进程不具备运行条件，正在等待某个时间完成的状态。 各状态之间的转换： 2。僵尸进程：进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait 获waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。 线程产生的原因：进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点： 引入线程就是为了解决以上进程的不足，线程具有以下的优点： 进程API以Unix系统为例，线程相关的API属于Posix线程(Pthreads)标准接口。 1 void exit(int status); 简述进程间通信方法进程如何通过管道进行通信 其本质是一个伪文件(实为内核缓冲区) 由两个文件描述符引用，一个表示读端，一个表示写端。 规定数据从管道的写端流入管道，从读端流出。 数据自己读不能自己写。 数据一旦被读走，便不在管道中存在，不可反复读取。 由于管道采用半双工通信方式。因此，数据只能在一个方向上流动。 只能在有公共祖先的进程间使用管道。 进程如何通过共享内存通信？ 共享内存是最快的一种IPC，因为进程是直接对内存进行操作来实现通信，避免了数据在用户空间和内核空间来回拷贝。 因为多个进程可以同时操作，所以需要进行同步处理。 信号量和共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。 什么是信号 发送信号：内核通过更新目的进程上下文中的某个状态，发送（递送）一个信号给目的进程。发送信号可以有如下两种原因： 内核检测到一个系统事件，比如除零错误或者子进程终止。 —个进程调用了kill 函数， 显式地要求内核发送一个信号给目的进程。一个进程可以发送信号给它自己。 接收信号：当目的进程被内核强迫以某种方式对信号的发送做出反应时，它就接收了信号。进程可以忽略这个信号，终止或者通过执行一个称为信号处理程序(signal handler)的用户层函数捕获这个信号。 如何编写正确且安全的信号处理函数 处理程序要尽可能简单。避免麻烦的最好方法是保持处理程序尽可能小和简单。例如，处理程序可能只是简单地设置全局标志并立即返回；所有与接收信号相关的处理都由主程序执行，它周期性地检查(并重置)这个标志。 在处理程序中只调用异步信号安全的函数。所谓异步信号安全的函数(或简称安全的函数)能够被信号处理程序安全地调用，原因有二：要么它是可重入的(例如只访问局部变量），要么它不能被信号处理程序中断。 保存和恢复errno。许多Linux 异步信号安全的函数都会在出错返回时设置errno在处理程序中调用这样的函数可能会干扰主程序中其他依赖于分。解决方法是在进人处理程序时把errno 保存在一个局部变量中，在处理程序返回前恢复它。注意，只有在处理程序要返回时才有此必要。如果处理程序调用_exit终止该进程，那么就不需要这样做了。 阻塞所有的信号，保护对共享全局数据结构的访问。如果处理程序和主程序或其他处理程序共享一个全局数据结构，那么在访问(读或者写)该数据结构时，你的处理程序和主程序应该暂时阻塞所有的信号。这条规则的原因是从主程序访问一个数据结构d 通常需要一系列的指令，如果指令序列被访问d 的处理程序中断，那么处理程序可能会发现d 的状态不一致，得到不可预知的结果。在访问d 时暂时阻塞信号保证了处理程序不会中断该指令序列。 用volatile 声明全局变量。考虑一个处理程序和一个main 函数，它们共享一个全局变量g 。处理程序更新g，main 周期性地读g， 对于一个优化编译器而言，main 中g的值看上去从来没有变化过，因此使用缓存在寄存器中g 的副本来满足对g 的每次引用是很安全的。如果这样，main 函数可能永远都无法看到处理程序更新过的值。可以用volatile 类型限定符来定义一个变量，告诉编译器不要缓存这个变量。例如：volatile 限定符强迫编译器毎次在代码中引用g时，都要从内存中读取g的值。一般来说，和其他所有共享数据结构一样，应该暂时阻塞信号，保护每次对全局变量的访问。 1 volatile int g; 用sig_atomic_t声明标志。在常见的处理程序设计中，处理程序会写全局标志来记录收到了信号。主程序周期性地读这个标志，响应信号，再清除该标志。对于通过这种方式来共享的标志，C 提供一种整型数据类型sig_atomic_t对它的读和写保证会是原子的（不可中断的）。 信号的一个与直觉不符的方面是未处理的信号是不排队的。因为 pending 位向量中每种类型的信号只对应有一位，所以每种类型最多只能有一个未处理的信号。关键思想是如果存在一个未处理的信号就表明至少有一个信号到达了。 进程调度的时机 当前运行的进程运行结束。 当前运行的进程由于某种原因阻塞。 执行完系统调用等系统程序后返回用户进程。 在使用抢占调度的系统中，具有更高优先级的进程就绪时。 分时系统中，分给当前进程的时间片用完。 不能进行进程调度的情况 在中断处理程序执行时。 在操作系统的内核程序临界区内。 其它需要完全屏蔽中断的原子操作过程中。 进程的调度策略 先到先服务调度算法 短作业优先调度算法 优先级调度算法 时间片轮转调度算法 高响应比优先调度算法 多级队列调度算法 多级反馈队列调度算法 进程调度策略的基本设计指标 CPU利用率 系统吞吐率，即单位时间内CPU完成的作业的数量。 响应时间。 周转时间。是指作业从提交到完成的时间间隔。从每个作业的角度看，完成每个作业的时间也是很关键 平均周转时间 带权周转时间 平均带权周转时间 进程的状态与状态转换 运行（running）态：进程占有处理器正在运行的状态。进程已获得CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态；在多处理机系统中，则有多个进程处于执行状态。 就绪→执行 处于就绪状态的进程，当进程调度程序为之分配了处理机后，该进程便由就绪状态转变成执行状态。 执行→就绪 处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完而不得不让出处理机，于是进程从执行状态转变成就绪状态。 执行→阻塞 正在执行的进程因等待某种事件发生而无法继续执行时，便从执行状态变成阻塞状态。 阻塞→就绪 处于阻塞状态的进程，若其等待的事件已经发生，于是进程由阻塞状态转变为就绪状态。 什么是孤儿进程？僵尸进程? 孤儿进程：父进程退出，子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被init进程（1号进程）所收养，并由init进程对他们完成状态收集工作。 什么是线程？ 是进程划分的任务，是一个进程内可调度的实体，是CPU调度的基本单位，用于保证程序的实时性，实现进程内部的并发。 线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。 每个线程完成不同的任务，但是属于同一个进程的不同线程之间共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。 为什么需要线程？ 进程在同一时刻只能做一个任务，很多时候不能充分利用CPU资源。 进程在执行的过程中如果发生阻塞，整个进程就会挂起，即使进程中其它任务不依赖于等待的资源，进程仍会被阻塞。 从资源上来讲，开辟一个线程所需要的资源要远小于一个进程。 从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间（这种时间的差异主要由于缓存的大量未命中导致）。 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的地址空间，要进行数据的传递只能通过进程间通信的方式进行。线程则不然，属于同一个进程的不同线程之间共享同一地址空间，所以一个线程的数据可以被其它线程感知，线程间可以直接读写进程数据段（如全局变量）来进行通信（需要一些同步措施）。 简述线程和进程的区别和联系 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。 进程在执行过程中拥有独立的地址空间，而多个线程共享进程的地址空间。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。） 进程是资源分配的最小单位，线程是CPU调度的最小单位。 通信：由于同一进程中的多个线程具有相同的地址空间，使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信（需要一些同步方法，以保证数据的一致性）。 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。 进程间不会相互影响；一个进程内某个线程挂掉将导致整个进程挂掉。 进程适应于多核、多机分布；线程适用于多核。 进程和线程的基本API 操作系统中，进程是具有不同的地址空间的，两个进程是不能感知到对方的存在的。有时候，需要多个进程来协同完成一些任务。当多个进程需要对同一个内核资源进行操作时，这些进程便是竞争的关系，操作系统必须协调各个进程对资源的占用，进程的互斥是解决进程间竞争关系的方法。进程互斥指若干个进程要使用同一共享资源时，任何时刻最多允许一个进程去使用，其他要使用该资源的进程必须等待，直到占有资源的进程释放该资源。当多个进程协同完成一些任务时，不同进程的执行进度不一致，这便产生了进程的同步问题。需要操作系统干预，在特定的同步点对所有进程进行同步，这种协作进程之间相互等待对方消息或信号的协调关系称为进程同步。进程互斥本质上也是一种进程同步。进程的同步方法： 操作系统中，属于同一进程的线程之间具有相同的地址空间，线程之间共享数据变得简单高效。遇到竞争的线程同时修改同一数据或是协作的线程设置同步点的问题时，需要使用一些线程同步的方法来解决这些问题。 线程同步的方法： 进程之间地址空间不同，不能感知对方的存在，同步时需要将锁放在多进程共享的空间。而线程之间共享同一地址空间，同步时把锁放在所属的同一进程空间即可。 死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。产生死锁需要满足下面四个条件： 解决死锁的方法即破坏产生死锁的四个必要条件之一，主要方法如下: 地址空间是一个非负整数地址的有序集合。 在一个带虚拟内存的系统中，CPU 从一个有N=pow(2,n)个地址的地址空间中生成虚拟地址，这个地址空间称为虚拟地址空间（virtual address space）,现代系统通常支持 32 位或者 64 位虚拟地址空间。 一个系统还有一个物理地址空间（physical address space），对应于系统中物理内存的M 个字节。 地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地址）。 一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间。这就是虚拟内存的基本思想。 主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。 为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟内存(VM)。虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。通过一个很清晰的机制，虚拟内存提供了三个重要的能力： 当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下： 当前最常采用的就是LRU算法。 实时操作系统（Real-time operating system, RTOS），又称即时操作系统，它会按照排序运行、管理系统资源，并为开发应用程序提供一致的基础。实时操作系统与一般的操作系统相比，最大的特色就是“实时性”，如果有一个任务需要执行，实时操作系统会马上（在较短时间内）执行该任务，不会有较长的延时。这种特性保证了各个任务的及时执行。 由于多进程共享资源，具有最高优先权的进程被低优先级进程阻塞，反而使具有中优先级的进程先于高优先级的进程执行，导致系统的崩溃。这就是所谓的优先级反转(Priority Inversion)。其实,优先级反转是在高优级(假设为A)的任务要访问一个被低优先级任务(假设为C)占有的资源时,被阻塞.而此时又有优先级高于占有资源的任务(C)而低于被阻塞的任务(A)的优先级的任务(假设为B)时,于是,占有资源的任务就被挂起(占有的资源仍为它占有),因为占有资源的任务优先级很低,所以,它可能一直被另外的任务挂起.而它占有的资源也就一直不能释放,这样,引起任务A一直没办法执行.而比它优先低的任务却可以执行。 目前解决优先级反转有许多种方法。其中普遍使用的有2种方法：一种被称作优先级继承(priority inheritance)；另一种被称作优先级极限(priority ceilings)。 select是一种多路复用技术。其收到所有输入的文件描述符，返回哪些文件有新数据。 其可以设置为阻塞或者非阻塞状态，底层采用1024位bitmap做实现，因此有文件描述符上限数。 poll是一种多路复用技术。其收到所有输入的文件描述符，返回哪些文件有新数据。 其通过链表代替了之前select的数据结构，使得其没有上限限制。 poll是一种多路复用技术。其采用一个文件描述符管理多个输入的文件描述符，采用事件回调的方式，提高了程序运行效率。 虚拟地址由虚拟页号和页偏移两部分组成。通过虚拟地址的页面号，首先在快表中查询是否有该映射，查询不成功，在页表中找到该页对应的物理地址。然后通过页物理地址+页偏移，得到真实的物理地址 页表用于存储虚拟地址中的虚拟页面号和物理页面号的映射关系。除此之外，有些页的读写有限制，页表也通过其他存储位，标记该页访问位，是否在内存中（可能被页面置换出去了）等等。 多级页表用于减少内存的占用。以二级页表为例，虚拟地址被分为DIR,PAGE和offset三部分，通过顶级页表和DIR，寻找到该二级页表的起始位置，再通过二级页表的起始位置和PAGE，找到页物理地址，最后加上页偏移，即可得到最终的物理地址。 快表也称为页表高速缓存。其会存储一定数量的页表项，以此加快虚拟地址到物理地址的映射速度。 MMU即内存管理单元，该硬件负责处理虚拟地址到物理地址的转化工作。快表也存储在MMU上。 先来先服务调度算法：创建一个任务队列，一旦有新任务就加入这个队列，CPU完成一个任务后就从队列取任务。 短作业(进程)优先调度算法：针对较短的作业，优先调给CPU工作。 时间片轮转算法：每个时间片依次执行一个任务，时间片结束后将该任务放回任务队列。 多级反馈队列：也按时间片轮转算法执行任务，设置n个队列，当第一个队列任务为空，才执行第二个队列，依次类推。如果在i队列的任务在该时间片执行后没有完成，即插入i+1号队列。 进程组即多个进程的集合,进程组有一个组长,组长进程的PID等于进程组的PGID。 协程，即用户态线程。我们知道，在Linux下，线程有PCB，然后可以占用时间片去调度，但是在用户态线程中，该线程的执行不由内核做调度，由用户自己实现 可以这么理解，在用户进程A中，再实现了个调度器，调度用户线程，这些线程不像之前的线程，内核是感知不到的，它们只能感知到A的存在，用户态线程之间时间片只能争取内核分给进程A的时间片。 多线程模型 多对一模型。将多个用户级线程映射到一个内核级线程上。该模型下，线程在用户空间进行管理，效率较高。缺点就是一个线程阻塞，整个进程内的所有线程都会阻塞。几乎没有系统继续使用这个模型。 一对一模型。将内核线程与用户线程一一对应。优点是一个线程阻塞时，不会影响到其它线程的执行。该模型具有更好的并发性。缺点是内核线程数量一般有上限，会限制用户线程的数量。更多的内核线程数目也给线程切换带来额外的负担。linux和Windows操作系统家族都是使用一对一模型。 多对多模型。将多个用户级线程映射到多个内核级线程上。结合了多对一模型和一对一模型的特点。 进程同步的方法 互斥锁 读写锁 条件变量 记录锁(record locking) 信号量 屏障（barrier） 线程同步的方法 互斥锁 读写锁 条件变量 信号量 自旋锁 屏障（barrier） 进程同步与线程同步有什么区别死锁是怎样产生的？ 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源。 占有并等待条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源。 非抢占条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放。 循环等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链。 如何解决死锁问题？ 资源一次性分配，这样就不会再有请求了（破坏请求条件）。 只要有一个资源得不到分配，也不给这个进程分配其他的资源（破坏占有并等待条件）。 可抢占资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可抢占的条件。 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 什么是虚拟地址，什么是物理地址？什么是虚拟内存？ 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 它为每个进程提供了一致的地址空间，从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。 为什么要引入虚拟内存？ 虚拟内存作为缓存的工具 虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组。 虚拟内存利用DRAM缓存来自通常更大的虚拟地址空间的页面。 虚拟内存作为内存管理的工具。操作系统为每个进程提供了一个独立的页表，也就是独立的虚拟地址空间。多个虚拟页面可以映射到同一个物理页面上。 一般：每个进程有各自私有的代码，数据，堆栈，是不和其他进程共享的，这样OS创建页表，将虚拟页映射到不连续的物理页面。 某些情况下，需要进程来共享代码和数据。例如每个进程调用相同的操作系统内核代码，或者C标准库函数。OS会把不同进程中适当的虚拟页面映射到相同的物理页面。 加载器从不在磁盘到内存实际复制任何数据，在每个页初次被引用时，虚拟内存系统会按照需要自动的调入数据页。 例如：一个给定的linux系统上的每个进程都是用类似的内存格式，对于64为地址空间，代码段总是从虚拟地址）0x400000开始，数据段，代码段，栈，堆等等。 简化链接： 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。 简化加载： 虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中.text和.data节加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页VP，把他们标记为无效（未被缓存） ，将页表条目指向目标文件的起始位置。 简化共享： 独立地址空间为OS提供了一个管理用户进程和操作系统自身之间共享的一致机制。 简化内存分配： 虚拟内存向用户提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如malloc），OS分配一个适当k大小个连续的虚拟内存页面，并且将他们映射到物理内存中任意位置的k个任意物理页面，因此操作系统没有必要分配k个连续的物理内存页面，页面可以随机的分散在物理内存中。 虚拟内存作为内存保护的工具。不应该允许一个用户进程修改它的只读段，也不允许它修改任何内核代码和数据结构，不允许读写其他进程的私有内存，不允许修改任何与其他进程共享的虚拟页面。每次CPU生成一个地址时，MMU会读一个PTE，通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。 常见的页面置换算法 先进先出(FIFO)算法： 思路：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。 实现：按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 特点：实现简单；性能较差，调出的页面可能是经常访问的 最近最少使用（LRU）算法: 思路：置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。 实现：缺页时，计算内存中每个逻辑页面的上一次访问时间，选择上一次使用到当前时间最长的页面 特点：可能达到最优的效果，维护这样的访问链表开销比较大 最不常用算法（Least Frequently Used, LFU） 思路：缺页时，置换访问次数最少的页面 实现：每个页面设置一个访问计数，访问页面时，访问计数加1，缺页时，置换计数最小的页面 特点：算法开销大，开始时频繁使用，但以后不使用的页面很难置换 请说一下什么是写时复制？ 如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。 写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork()调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 实时操作系统的概念优先级反转是什么？如何解决 优先级继承(priority inheritance) 优先级继承是指将低优先级任务的优先级提升到等待它所占有的资源的最高优先级任务的优先级.当高优先级任务由于等待资源而被阻塞时,此时资源的拥有者的优先级将会自动被提升。 优先级天花板(priority ceilings)优先级天花板是指将申请某资源的任务的优先级提升到可能访问该资源的所有任务中最高优先级任务的优先级.(这个优先级称为该资源的优先级天花板)。 简述 selectselect是一种多路复用技术。其收到所有输入的文件描述符，返回哪些文件有新数据。其可以设置为阻塞或者非阻塞状态，底层采用1024位bitmap做实现，因此有文件描述符上限数。 简述pollpoll是一种多路复用技术。其收到所有输入的文件描述符，返回哪些文件有新数据。其通过链表代替了之前select的数据结构，使得其没有上限限制。 简述epollpoll是一种多路复用技术。其采用一个文件描述符管理多个输入的文件描述符，采用事件回调的方式，提高了程序运行效率。 简述虚拟地址到物理地址转化过程虚拟地址由虚拟页号和页偏移两部分组成。通过虚拟地址的页面号，首先在快表中查询是否有该映射，查询不成功，在页表中找到该页对应的物理地址。然后通过页物理地址+页偏移，得到真实的物理地址 简述页表页表用于存储虚拟地址中的虚拟页面号和物理页面号的映射关系。除此之外，有些页的读写有限制，页表也通过其他存储位，标记该页访问位，是否在内存中（可能被页面置换出去了）等等。 简述多级页表多级页表用于减少内存的占用。以二级页表为例，虚拟地址被分为DIR,PAGE和offset三部分，通过顶级页表和DIR，寻找到该二级页表的起始位置，再通过二级页表的起始位置和PAGE，找到页物理地址，最后加上页偏移，即可得到最终的物理地址。 简述快表快表也称为页表高速缓存。其会存储一定数量的页表项，以此加快虚拟地址到物理地址的映射速度。 简述MMUMMU即内存管理单元，该硬件负责处理虚拟地址到物理地址的转化工作。快表也存储在MMU上。 进程调度算法先来先服务调度算法：创建一个任务队列，一旦有新任务就加入这个队列，CPU完成一个任务后就从队列取任务。短作业(进程)优先调度算法：针对较短的作业，优先调给CPU工作。时间片轮转算法：每个时间片依次执行一个任务，时间片结束后将该任务放回任务队列。多级反馈队列：也按时间片轮转算法执行任务，设置n个队列，当第一个队列任务为空，才执行第二个队列，依次类推。如果在i队列的任务在该时间片执行后没有完成，即插入i+1号队列。 简述进程组进程组即多个进程的集合,进程组有一个组长,组长进程的PID等于进程组的PGID。 简述协程协程，即用户态线程。我们知道，在Linux下，线程有PCB，然后可以占用时间片去调度，但是在用户态线程中，该线程的执行不由内核做调度，由用户自己实现可以这么理解，在用户进程A中，再实现了个调度器，调度用户线程，这些线程不像之前的线程，内核是感知不到的，它们只能感知到A的存在，用户态线程之间时间片只能争取内核分给进程A的时间片。","link":"/2022/05/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"后端开发","slug":"java/后端开发","link":"/categories/java/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"search","text":"","link":"/search/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}]}